{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook processes some of the raw FAC data\n",
    "* FAC data from 2014-2018 was downloaded in bulk from https://harvester.census.gov/facdissem/PublicDataDownloads.aspx\n",
    "* Certain fields of interest are extracted from findings.txt and general.txt\n",
    "* Agency prefix and entity codes tables were generated by hand\n",
    "* All processed data is saved as pickles in /data/ihwang/data_journalism/allfac/processed for easy access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process findings.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fac_path = '/data/ihwang/data_journalism/allfac'\n",
    "findings = '/raw/findings.txt'\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "data = []\n",
    "with open(fac_path + findings, 'r') as f:\n",
    "    for line in f:\n",
    "        if line[0] != ' ':\n",
    "            header = line.split(',')\n",
    "        else:\n",
    "            fields = re.sub('\\s', '', line).split(',')\n",
    "            [DBKEY,AUDITYEAR,ELECAUDITSID,\n",
    "             ELECAUDITFINDINGSID] = [int(field) for field in fields[:4]]\n",
    "            # Can be multiple FINDINGSREFNUMS which makes it necessary to parse\n",
    "            # file line-by-line (instead of using pandas.csv_read)\n",
    "            [*FINDINGSREFNUMS] = fields[4:-9]\n",
    "            [TYPEREQUIREMENT, MODIFIEDOPINION,OTHERNONCOMPLIANCE,\n",
    "             MATERIALWEAKNESS,SIGNIFICANTDEFICIENCY,OTHERFINDINGS,QCOSTS,\n",
    "             REPEATFINDING,PRIORFINDINGREFNUMS] = fields[-9:]\n",
    "            data.append(\n",
    "                [\n",
    "                    DBKEY,AUDITYEAR,ELECAUDITSID,ELECAUDITFINDINGSID,\n",
    "                    FINDINGSREFNUMS, TYPEREQUIREMENT,MODIFIEDOPINION,\n",
    "                    OTHERNONCOMPLIANCE,MATERIALWEAKNESS,\n",
    "                    SIGNIFICANTDEFICIENCY,OTHERFINDINGS,QCOSTS,\n",
    "                    REPEATFINDING,PRIORFINDINGREFNUMS\n",
    "                ]\n",
    "            )\n",
    "findings_all = pd.DataFrame(data, columns=header)\n",
    "findings_df = findings_all[\n",
    "    [\n",
    "        'DBKEY', 'AUDITYEAR', 'TYPEREQUIREMENT', 'MODIFIEDOPINION', \n",
    "        'OTHERNONCOMPLIANCE','MATERIALWEAKNESS', 'SIGNIFICANTDEFICIENCY',\n",
    "        'OTHERFINDINGS', 'QCOSTS'\n",
    "    ]\n",
    "]\n",
    "findings_df.head()\n",
    "findings_df.to_pickle(fac_path + '/processed/findings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DBKEY', 'AUDITYEAR', 'ELECAUDITSID', 'ELECAUDITFINDINGSID',\n",
       "       'FINDINGSREFNUMS', 'TYPEREQUIREMENT', 'MODIFIEDOPINION',\n",
       "       'OTHERNONCOMPLIANCE', 'MATERIALWEAKNESS', 'SIGNIFICANTDEFICIENCY',\n",
       "       'OTHERFINDINGS', 'QCOSTS', 'REPEATFINDING',\n",
       "       'PRIORFINDINGREFNUMS                                                                                                                                                                                                         \\n'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findings_all.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process general.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fac_path = '/data/ihwang/data_journalism/allfac/'\n",
    "general = '/raw/general.txt'\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "general_all = pd.read_csv(\n",
    "    fac_path + general, encoding = 'ISO-8859-1', low_memory=False\n",
    ")  # low memory parameter for mixed types\n",
    "general_df = general_all[\n",
    "    [\n",
    "        'DBKEY', 'AUDITYEAR', 'STATE', 'CPASTATE', 'CPAPHONE',\n",
    "        'TYPEOFENTITY', 'OVERSIGHTAGENCY', 'TOTFEDEXPEND',\n",
    "        'REPORTABLECONDITION', 'MATERIALWEAKNESS', 'MATERIALNONCOMPLIANCE',\n",
    "        'REPORTABLECONDITION_MP', 'MATERIALWEAKNESS_MP', 'QCOSTS'\n",
    "    ]\n",
    "]\n",
    "general_df = general_df.assign(\n",
    "    AUDITEENAME=general_all['AUDITEENAME'].str.strip().str.replace(r'[^\\w\\s]', '')\n",
    ")\n",
    "general_df = general_df.assign(\n",
    "    CPAFIRMNAME=general_all['CPAFIRMNAME'].str.strip().str.replace(r'[^\\w\\s]', '')\n",
    ")\n",
    "general_df = general_df.assign(\n",
    "    CPACONTACT=general_all['CPACONTACT'].str.strip().str.replace(r'[^\\w\\s]', '')\n",
    ")\n",
    "general_df = general_df.assign(\n",
    "    CPATITLE=general_all['CPATITLE'].str.strip().str.replace(r'[^\\w\\s]', '')\n",
    ")\n",
    "general_df = general_df.assign(\n",
    "    ZIPCODE=pd.to_numeric(general_all['ZIPCODE'].str[:5], errors='coerce')\n",
    ")\n",
    "general_df = general_df.assign(\n",
    "    CPAZIPCODE=pd.to_numeric(general_all['CPAZIPCODE'].str[:5], errors='coerce')\n",
    ")\n",
    "general_df = general_df.assign(\n",
    "    TYPEREPORT_FS=general_all['TYPEREPORT_FS'].str.strip()\n",
    ")\n",
    "general_df = general_df.assign(\n",
    "    TYPEREPORT_MP=general_all['TYPEREPORT_MP'].str.strip()\n",
    ")\n",
    "general_df = general_df.assign(\n",
    "    CITY=general_all['CITY'].str.strip()\n",
    ")\n",
    "general_df = general_df.assign(\n",
    "    CPACITY=general_all['CPACITY'].str.strip()\n",
    ")\n",
    "general_df = general_df.assign(\n",
    "    EIN=pd.to_numeric(general_all['EIN'].str.split('-').str.get(-1))\n",
    ")\n",
    "general_df.apply(lambda x: x.str.upper() if(x.dtype == 'object') else x)  # convert all text to uppercase\n",
    "general_df.head()\n",
    "general_df.to_pickle(fac_path + 'processed/general.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DBKEY', 'AUDITYEAR', 'STATE', 'CPASTATE', 'CPAPHONE', 'TYPEOFENTITY',\n",
      "       'OVERSIGHTAGENCY', 'TOTFEDEXPEND', 'REPORTABLECONDITION',\n",
      "       'MATERIALWEAKNESS', 'MATERIALNONCOMPLIANCE', 'REPORTABLECONDITION_MP',\n",
      "       'MATERIALWEAKNESS_MP', 'QCOSTS', 'AUDITEENAME', 'CPAFIRMNAME',\n",
      "       'CPACONTACT', 'CPATITLE', 'ZIPCODE', 'CPAZIPCODE', 'TYPEREPORT_FS',\n",
      "       'TYPEREPORT_MP', 'CITY', 'CPACITY', 'EIN'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(general_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Process agency prefix table\n",
    "Raw data copied and pasted from https://harvester.census.gov/facdissem/Documents/PublicUserManual.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "fac_path = '/data/ihwang/data_journalism/allfac'\n",
    "prefix_table = '/raw/manual/prefix_table.txt'\n",
    "\n",
    "\n",
    "agency_dict = {}\n",
    "with open(fac_path + prefix_table, 'r') as f:\n",
    "    for line in f:\n",
    "        data = line.strip().split(' ')\n",
    "        prefix = data[0]\n",
    "        agency = data[1:-1]\n",
    "        agency_dict[prefix] = ' '.join(agency)\n",
    "        \n",
    "        \n",
    "with open(fac_path + '/processed/agency_dict.pkl', 'wb') as f_w:\n",
    "    pickle.dump(agency_dict, f_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process entity codes table\n",
    "Raw data copied and pasted from https://harvester.census.gov/facdissem/Documents/PublicUserManual.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fac_path = '/data/ihwang/data_journalism/allfac'\n",
    "entity_table = '/raw/manual/entity_table.txt'\n",
    "\n",
    "\n",
    "entity_dict = {}\n",
    "with open(fac_path + entity_table, 'r') as f:\n",
    "    for line in f:\n",
    "        data = line.strip().split(' ')\n",
    "        entity = data[:-1]\n",
    "        code = data[-1]\n",
    "        entity_dict[code] = ' '.join(entity)\n",
    "        \n",
    "        \n",
    "with open(fac_path + '/processed/entity_dict.pkl', 'wb') as f_w:\n",
    "    pickle.dump(entity_dict, f_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
